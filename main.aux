\relax 
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{Introduction}{3}}
\citation{toulouse}
\citation{calculNeuronal}
\@writefile{toc}{\contentsline {section}{\numberline {1}Generalities}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Biologic neuron}{5}}
\citation{calculNeuronal}
\citation{calculNeuronal}
\citation{calculNeuronal}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  Schematic representation of the biological neuron.  1 - The dendritic tree;  2 - Soma (cell body);  3 - The core of the neuronal cell;  4 - The axon;  5 - The axon tree;  6 - Synaptic connections. \relax }}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Artificial neuron}{7}}
\citation{calculNeuronal}
\citation{calculNeuronal}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Semantic representation of semantic neuron\relax }}{9}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:artificialNeuron}{{2}{9}}
\newlabel{obs:bias}{{1}{9}}
\citation{autoriFundamentali}
\citation{Rumelhart}
\citation{Cottrell}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Areas of use of neural networks}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Processing of natural languages}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2}Compression of multidimensional data}{10}}
\citation{Bishop}
\citation{oecd}
\citation{Fukushima1}
\citation{Fukushima2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.3}Character Recognition}{11}}
\@writefile{toc}{\contentsline {paragraph}{Handwriting recognition.}{11}}
\@writefile{toc}{\contentsline {paragraph}{Image processing.}{11}}
\citation{calculNeuronal}
\@writefile{toc}{\contentsline {section}{\numberline {2}Machine learning}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Supervised learning}{13}}
\citation{Baum}
\citation{Haykin}
\citation{Girolami}
\citation{Sanger1}
\citation{Sanger2}
\citation{Barlow}
\citation{Diamantaras}
\citation{Diamantaras}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Diagram of supervised learning.\relax }}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Unsupervised learning}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Unsupervised Learning Diagram.\relax }}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Learning optimizer}{15}}
\citation{Diederik}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Adam optimizer}{16}}
\newlabel{alg:adamOptimizer}{{13}{17}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Adam, proposed algorithm for stochastic optimization.\relax }}{17}}
\citation{Diederik}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}AdaGrad optimizer}{18}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Gradient descendent optimizer}{18}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.4}RMSprop optimizer}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Recurrent neural network}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Recurrent Neural Networks with loops.\relax }}{20}}
\newlabel{fig:rnnRoll}{{5}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Unrolled recurrent neural network.\relax }}{20}}
\newlabel{fig:rnnUnroll}{{6}{20}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Bidirectional RNNs}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces General Structure of Bidirectional Recurrent Neural Networks.\relax }}{21}}
\newlabel{fig:bidirectionalRNN}{{7}{21}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Deep (Bidirectional) RNNs}{22}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.3}LSTM networks}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Graphics representation for connecting informations\relax }}{22}}
\citation{lstm}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Graphics representation for connecting informations, more data\relax }}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The repeating module in a standard RNN contains a single layer.\relax }}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The repeating module in an LSTM contains four interacting layers.\relax }}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Conditional random field}{24}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}Keyword extraction}{26}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.2}Named entity extraction}{26}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.3}Time expressions extraction}{27}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.4}Sentiment Analysis}{27}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Implementation}{29}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Why python?}{29}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Tensor flow}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Trivial tensor example.\relax }}{32}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Graph}{32}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Session}{33}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Placeholder}{33}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}Variable}{34}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.5}Scope}{36}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.6}Loss}{38}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.7}Logits}{38}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.8}Feed}{38}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.9}Tensor}{39}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.10}Static shape}{40}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.11}Dynamic shape}{41}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Named entry recognition}{43}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Glove}{43}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Prepare data}{44}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}Read data}{45}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2}Make vocabular}{46}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Build graph}{46}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3}Add placeholders}{46}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4}Add word embeddings}{47}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5}Add char embeddings}{48}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {6}Apply bi-LSTM to char embeddings}{48}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7}Randomize the word embeddings}{49}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {8}Apply bi-LSTM to word embeddings}{49}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {9}Add last layout}{50}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {10}Add loss and optimizer}{50}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Final graph\relax }}{51}}
\newlabel{fig:finalGraph}{{13}{51}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {11}Train network}{51}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {12}Make embeddings}{53}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {13}Feed network}{54}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {14}Test network}{55}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.4}Tests}{56}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {15}Network configurations}{56}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {16}Network results during training}{57}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Some of the interactive results\relax }}{58}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Loss diagram\relax }}{58}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Distance for word "York"\relax }}{59}}
\@writefile{toc}{\contentsline {section}{Conclusion}{60}}
\bibstyle{plain}
\bibdata{references}
