\section*{Introduction}
\addcontentsline{toc}{section}{Introduction}


The human brain has been compared to an information processing system since ancient times. Since 1943, when Warren McCulloch and Walter Pitts presented the first model of artificial neurons. New and more sophisticated proposals have been made from one decade to the next. The mathematical analysis solved some of the mysteries represented by the new models, but left many open questions for future investigations.

The study of neurons, and their interconnections is one of the most dynamic and important fields of research in modern biology. The human brain can be considered faster and more powerful than the most powerful super computer ever built by humans. He has the ability to organize his neural activity in such a way as to perform complex activities: form recognition, perception, motor control, etc. The brain succeeds in about 100-200 ms. to solve a complex problem like that of recognizing a person, while a computing system requires much more time for simpler tasks. The question "How does the human brain work? " Is far from being known.

Artificial neural networks are an attempt to model the capacity of the nervous system to process information. Taking into account the essential properties of biological neural networks in terms of information, abstract models of artificial neural networks can be designed, which can then be simulated and analyzed.

Perceptron with a single layer is the simplest neural network. This elementary and simple network has the ability to learn to recognize simple forms. The simple perceptron teaches with the help of a supervised learning law how to learn. The simple Perceptron architecture consists of the input layer and the exit layer. It haven't hidden layers.

From the Perceptron model, other neural networks, including the BackPropagation network, have been developed. BackPropagation networks are direct-acting neural networks. That contain input nodes, ouput nodes and one or more layers of nodes between these two. These additional layers represent the hidden levels of multilayer perceptrons.

This paper aims to put neural networks into practice for classifying text data.
 
In Chapter 1 there are some general notions about "neurons" and neural networks. Also are some of the areas covered by these neural networks and how their working.
 
in chapter 2 are presented two ways of learning neural networks (supervised learning and unsupervised learning). Here are some ways to optimize neural networks. These are perfect for shortening your learning time as well as increasing your success rate. It will also show how recurring neural networks work to classify text data.
 
In Chapter 3 will be implemented a model for classifying text data. Python will be used for this. To ease the construction of the neural model, the Tensor Flow framework will be used. Also, the performance of the algorithm will be highlighted by altering different neural optimization. The model will also be tested with pre-trained Glove data. Glove is an unsupervised neural network.